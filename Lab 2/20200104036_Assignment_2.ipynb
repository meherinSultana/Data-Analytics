{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6e3qazVriIT"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Install Spark (change the version number if needed)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.3/spark-3.0.3-bin-hadoop3.2.tgz\n",
        "\n",
        "# Unzip the Spark file to the current folder\n",
        "!tar xf spark-3.0.3-bin-hadoop3.2.tgz\n",
        "\n",
        "# Install findspark\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop3.2\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBls2CnIBL-9",
        "outputId": "5656cb61-1ca6-4d53-a556-59706f2bbe1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"CreateDataFrame\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Define schema for the DataFrame\n",
        "schema = StructType([\n",
        "    StructField(\"emp_id\", IntegerType(), True),\n",
        "    StructField(\"emp_name\", StringType(), True),\n",
        "    StructField(\"job_name\", StringType(), True),\n",
        "    StructField(\"manager_id\", IntegerType(), True),\n",
        "    StructField(\"hire_date\", StringType(), True),\n",
        "    StructField(\"salary\", FloatType(), True),\n",
        "    StructField(\"commission\", FloatType(), True),\n",
        "    StructField(\"dep_id\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "# Create a list of tuples containing the data\n",
        "data = [\n",
        "    (68319, \"KAYLING\", \"PRESIDENT\", None, \"1991-11-18\", 6000.00, None, 1001),\n",
        "    (66928, \"BLAZE\", \"MANAGER\", 68319, \"1991-05-01\", 2750.00, None, 3001),\n",
        "    (67832, \"CLARE\", \"MANAGER\", 68319, \"1991-06-09\", 2550.00, None, 1001),\n",
        "    (65646, \"JONAS\", \"MANAGER\", 68319, \"1991-04-02\", 2957.00, None, 2001),\n",
        "    (67858, \"SCARLET\", \"ANALYST\", 65646, \"1997-04-19\", 3100.00, None, 2001),\n",
        "    (69062, \"FRANK\", \"ANALYST\", 65646, \"1991-12-03\", 3100.00, None, 2001),\n",
        "    (63679, \"SANDRINE\", \"CLERK\", 69062, \"1990-12-18\", 900.00, None, 2001),\n",
        "    (64989, \"ADELYN\", \"SALESMAN\", 66928, \"1991-02-20\", 1700.00, 400.00, 3001),\n",
        "    (65271, \"WADE\", \"SALESMAN\", 66928, \"1991-02-22\", 1350.00, 600.00, 3001),\n",
        "    (66564, \"MADDEN\", \"SALESMAN\", 66928, \"1991-09-28\", 1350.00, 1500.00, 3001),\n",
        "    (68454, \"TUCKER\", \"SALESMAN\", 66928, \"1991-09-08\", 1600.00, 0.00, 3001),\n",
        "    (68736, \"ADNRES\", \"CLERK\", 67858, \"1997-05-23\", 1200.00, None, 2001),\n",
        "    (69000, \"JULIUS\", \"CLERK\", 66928, \"1991-12-03\", 1050.00, None, 3001),\n",
        "    (69324, \"MARKER\", \"CLERK\", 67832, \"1992-01-23\", 1400.00, None, 1001)\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "emp_df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# Show DataFrame\n",
        "emp_df.show()\n",
        "department_schema = StructType([\n",
        "    StructField(\"dep_id\", IntegerType(), True),\n",
        "    StructField(\"dep_name\", StringType(), True),\n",
        "    StructField(\"dep_location\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Create a list of tuples containing department data\n",
        "department_data = [\n",
        "    (1001, \"FINANCE\", \"SYDNEY\"),\n",
        "    (2001, \"AUDIT\", \"MELBOURNE\"),\n",
        "    (3001, \"MARKETING\", \"PERTH\"),\n",
        "    (4001, \"PRODUCTION\", \"BRISBANE\")\n",
        "]\n",
        "dep_df = spark.createDataFrame(department_data, department_schema)\n",
        "\n",
        "# Show Department DataFrame\n",
        "dep_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS0fEv28ru2W",
        "outputId": "8af7d426-cf21-44c4-c7fd-d07ede9074ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---------+----------+----------+------+----------+------+\n",
            "|emp_id|emp_name| job_name|manager_id| hire_date|salary|commission|dep_id|\n",
            "+------+--------+---------+----------+----------+------+----------+------+\n",
            "| 68319| KAYLING|PRESIDENT|      null|1991-11-18|6000.0|      null|  1001|\n",
            "| 66928|   BLAZE|  MANAGER|     68319|1991-05-01|2750.0|      null|  3001|\n",
            "| 67832|   CLARE|  MANAGER|     68319|1991-06-09|2550.0|      null|  1001|\n",
            "| 65646|   JONAS|  MANAGER|     68319|1991-04-02|2957.0|      null|  2001|\n",
            "| 67858| SCARLET|  ANALYST|     65646|1997-04-19|3100.0|      null|  2001|\n",
            "| 69062|   FRANK|  ANALYST|     65646|1991-12-03|3100.0|      null|  2001|\n",
            "| 63679|SANDRINE|    CLERK|     69062|1990-12-18| 900.0|      null|  2001|\n",
            "| 64989|  ADELYN| SALESMAN|     66928|1991-02-20|1700.0|     400.0|  3001|\n",
            "| 65271|    WADE| SALESMAN|     66928|1991-02-22|1350.0|     600.0|  3001|\n",
            "| 66564|  MADDEN| SALESMAN|     66928|1991-09-28|1350.0|    1500.0|  3001|\n",
            "| 68454|  TUCKER| SALESMAN|     66928|1991-09-08|1600.0|       0.0|  3001|\n",
            "| 68736|  ADNRES|    CLERK|     67858|1997-05-23|1200.0|      null|  2001|\n",
            "| 69000|  JULIUS|    CLERK|     66928|1991-12-03|1050.0|      null|  3001|\n",
            "| 69324|  MARKER|    CLERK|     67832|1992-01-23|1400.0|      null|  1001|\n",
            "+------+--------+---------+----------+----------+------+----------+------+\n",
            "\n",
            "+------+----------+------------+\n",
            "|dep_id|  dep_name|dep_location|\n",
            "+------+----------+------------+\n",
            "|  1001|   FINANCE|      SYDNEY|\n",
            "|  2001|     AUDIT|   MELBOURNE|\n",
            "|  3001| MARKETING|       PERTH|\n",
            "|  4001|PRODUCTION|    BRISBANE|\n",
            "+------+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_df.createOrReplaceTempView(\"employees\")\n",
        "dep_df.createOrReplaceTempView(\"departments\")\n",
        "\n",
        "result = spark.sql(\"SELECT emp_name, dep_name FROM employees JOIN departments ON employees.dep_id = departments.dep_id\")\n",
        "result.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCOzsLzvswEQ",
        "outputId": "f60938d8-23a3-4519-8da9-3e46497131ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+\n",
            "|emp_name| dep_name|\n",
            "+--------+---------+\n",
            "|   BLAZE|MARKETING|\n",
            "|  ADELYN|MARKETING|\n",
            "|    WADE|MARKETING|\n",
            "|  MADDEN|MARKETING|\n",
            "|  TUCKER|MARKETING|\n",
            "|  JULIUS|MARKETING|\n",
            "| KAYLING|  FINANCE|\n",
            "|   CLARE|  FINANCE|\n",
            "|  MARKER|  FINANCE|\n",
            "|   JONAS|    AUDIT|\n",
            "| SCARLET|    AUDIT|\n",
            "|   FRANK|    AUDIT|\n",
            "|SANDRINE|    AUDIT|\n",
            "|  ADNRES|    AUDIT|\n",
            "+--------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = spark.sql(\"SELECT employees.emp_name, managers.emp_name \\\n",
        "                    FROM employees \\\n",
        "                    JOIN employees managers ON employees.manager_id = managers.emp_id \\\n",
        "                    WHERE employees.manager_id IS NOT NULL\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B02PTCmUunMq",
        "outputId": "9c9032ff-2b70-4c86-f86c-5751e41b88f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+\n",
            "|emp_name|emp_name|\n",
            "+--------+--------+\n",
            "|  MARKER|   CLARE|\n",
            "|  ADELYN|   BLAZE|\n",
            "|    WADE|   BLAZE|\n",
            "|  MADDEN|   BLAZE|\n",
            "|  TUCKER|   BLAZE|\n",
            "|  JULIUS|   BLAZE|\n",
            "|SANDRINE|   FRANK|\n",
            "| SCARLET|   JONAS|\n",
            "|   FRANK|   JONAS|\n",
            "|   BLAZE| KAYLING|\n",
            "|   CLARE| KAYLING|\n",
            "|   JONAS| KAYLING|\n",
            "|  ADNRES| SCARLET|\n",
            "+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = spark.sql(\"SELECT employees.emp_name, COALESCE(managers.emp_name, 'No Manager') AS manager_name \\\n",
        "                    FROM employees \\\n",
        "                    LEFT JOIN employees managers ON employees.manager_id = managers.emp_id\")\n",
        "\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_2OFHrOvhbP",
        "outputId": "ff033888-b70c-4ac8-942b-1388c34af14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------+\n",
            "|emp_name|manager_name|\n",
            "+--------+------------+\n",
            "| KAYLING|  No Manager|\n",
            "|  MARKER|       CLARE|\n",
            "|  ADELYN|       BLAZE|\n",
            "|    WADE|       BLAZE|\n",
            "|  MADDEN|       BLAZE|\n",
            "|  TUCKER|       BLAZE|\n",
            "|  JULIUS|       BLAZE|\n",
            "|SANDRINE|       FRANK|\n",
            "| SCARLET|       JONAS|\n",
            "|   FRANK|       JONAS|\n",
            "|   BLAZE|     KAYLING|\n",
            "|   CLARE|     KAYLING|\n",
            "|   JONAS|     KAYLING|\n",
            "|  ADNRES|     SCARLET|\n",
            "+--------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = spark.sql(\"SELECT employees.emp_name \\\n",
        "                    FROM employees \\\n",
        "                    LEFT JOIN employees managers ON employees.manager_id = managers.emp_id \\\n",
        "                    WHERE managers.emp_id IS NULL\")\n",
        "\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAlaUQ9Mv_zX",
        "outputId": "89b610c8-ef12-4648-e675-134cf16c608d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|emp_name|\n",
            "+--------+\n",
            "| KAYLING|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = spark.sql(\"SELECT managers.emp_name, COUNT(employees.emp_id) AS num_employees \\\n",
        "                    FROM employees managers \\\n",
        "                    LEFT JOIN employees ON managers.emp_id = employees.manager_id \\\n",
        "                    GROUP BY managers.emp_id, managers.emp_name \\\n",
        "                    ORDER BY num_employees DESC \\\n",
        "                    LIMIT 1\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn2qmFeLwN2v",
        "outputId": "85708c98-bdec-4e8c-bba7-dd82f23f375a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------+\n",
            "|emp_name|num_employees|\n",
            "+--------+-------------+\n",
            "|   BLAZE|            5|\n",
            "+--------+-------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}